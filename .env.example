# =============================================================
# physical-ai-stl â€” Example environment file
# =============================================================
#
# Usage:
#   cp .env.example .env
#   source .env
#
# Notes:
# - Intended for POSIX shells (bash/zsh).  Windows uses a different path separator
#   for PYTHONPATH (semicolon ';' instead of colon ':').
# - Defaults are "CPU-first" + "demo-safe" (predictable, laptop-friendly).
# - Most settings use "${VAR:-default}" so you can override by pre-setting VAR
#   before sourcing, e.g.:
#       OMP_NUM_THREADS=8 source .env
# - Keep secrets out of this file (and out of git).
#
# =============================================================

# --- Project paths / imports -----------------------------------------------
# Add local package to import path.
# (Avoid a trailing ':' when PYTHONPATH is empty.)
export PYTHONPATH="$(pwd)/src${PYTHONPATH:+:${PYTHONPATH}}"

# Put caches inside the repo (keeps home dirs clean for demos/CI/grading).
export XDG_CACHE_HOME="${XDG_CACHE_HOME:-$(pwd)/.cache}"
export MPLCONFIGDIR="${MPLCONFIGDIR:-$(pwd)/.mplconfig}"
export PYTHONPYCACHEPREFIX="${PYTHONPYCACHEPREFIX:-$(pwd)/.pycache}"

# Optional: stable timestamps (useful for reproducible figure filenames).
export TZ="${TZ:-UTC}"

# --- Locale / encoding ------------------------------------------------------
# Ensure consistent UTF-8 logs/paths across machines.
export LC_ALL="${LC_ALL:-C.UTF-8}"
export LANG="${LANG:-C.UTF-8}"
export PYTHONUTF8="${PYTHONUTF8:-1}"
export PYTHONIOENCODING="${PYTHONIOENCODING:-UTF-8}"

# --- Reproducibility / determinism knobs -----------------------------------
# Python hash randomization (affects dict/set iteration order, etc.)
export PYTHONHASHSEED="${PYTHONHASHSEED:-0}"

# Tests read this seed; you can also reuse it in CLI overrides for scripts.
export TEST_SEED="${TEST_SEED:-0}"

# CUDA determinism (no-op on CPU). Still call torch.use_deterministic_algorithms(True) in code.
export CUBLAS_WORKSPACE_CONFIG="${CUBLAS_WORKSPACE_CONFIG:-:16:8}"

# Some libraries look for these flags; safe as no-ops if unused.
export TORCH_DETERMINISTIC="${TORCH_DETERMINISTIC:-1}"

# CUDA device-side assertions are great for debugging, but can slow GPU kernels.
export TORCH_USE_CUDA_DSA="${TORCH_USE_CUDA_DSA:-0}"

# Thread caps: keep CPU demos predictable and avoid "my laptop is melting".
# Override these if you want faster training on a workstation.
export OMP_NUM_THREADS="${OMP_NUM_THREADS:-1}"
export MKL_NUM_THREADS="${MKL_NUM_THREADS:-1}"
export NUMEXPR_NUM_THREADS="${NUMEXPR_NUM_THREADS:-1}"
export OPENBLAS_NUM_THREADS="${OPENBLAS_NUM_THREADS:-1}"
export VECLIB_MAXIMUM_THREADS="${VECLIB_MAXIMUM_THREADS:-1}"

# --- Python runtime hygiene -------------------------------------------------
export PYTHONFAULTHANDLER="${PYTHONFAULTHANDLER:-1}"
export PYTHONUNBUFFERED="${PYTHONUNBUFFERED:-1}"
export PYTHONDONTWRITEBYTECODE="${PYTHONDONTWRITEBYTECODE:-1}"

# Warnings:
# - For demos, keeping output clean is useful.
# - For debugging, consider: PYTHONWARNINGS=default
export PYTHONWARNINGS="${PYTHONWARNINGS:-ignore}"

# --- Paths (data / artifacts) ----------------------------------------------
# Keep all artifacts inside the repo by default.
export DATA_ROOT="${DATA_ROOT:-$(pwd)/data}"
export RESULTS_DIR="${RESULTS_DIR:-$(pwd)/results}"
export LOG_DIR="${LOG_DIR:-$(pwd)/logs}"
export FIG_DIR="${FIG_DIR:-$(pwd)/figs}"

# Tip (paper/report): capture system info once per machine/run, e.g.:
#   mkdir -p "$LOG_DIR" && python scripts/check_env.py | tee "$LOG_DIR/sysinfo.txt"

# Tip (paper/report): collect simple runtime + dependency snapshots, e.g.:
#   /usr/bin/time -v python scripts/run_experiment.py -c configs/diffusion1d_stl.yaml --set training.epochs=200 \
#     2>&1 | tee "$LOG_DIR/time_diffusion1d_stl.txt"
#   python -m pip freeze | tee "$LOG_DIR/pip_freeze.txt"

# --- Optional stacks toggles ------------------------------------------------
# Placeholder switches (conventions) if you want to gate heavy imports locally.
# (Currently informational; safe to leave as-is.)
export PHYSICAL_AI_STL_ALLOW_HEAVY_IMPORTS="${PHYSICAL_AI_STL_ALLOW_HEAVY_IMPORTS:-0}"
# export PHYSICAL_AI_STL_ENABLE_NEUROMANCER=1
# export PHYSICAL_AI_STL_ENABLE_PHYSICNEMO=1
# export PHYSICAL_AI_STL_ENABLE_TORCHPHYSICS=1

# If you want to skip import-time probing of optional backends (slightly faster):
# export PAI_STL_NO_PROBE=1

# --- Matplotlib / plotting --------------------------------------------------
# Headless backend (safe on SSH/CI).
export MPLBACKEND="${MPLBACKEND:-Agg}"

# --- PyTorch / device selection --------------------------------------------
# Prefer CPU by default; allow MPS fallback on macOS.
export PYTORCH_ENABLE_MPS_FALLBACK="${PYTORCH_ENABLE_MPS_FALLBACK:-1}"
export TORCH_CPP_LOG_LEVEL="${TORCH_CPP_LOG_LEVEL:-ERROR}"

# Uncomment to force CPU-only even if CUDA is installed:
# export CUDA_VISIBLE_DEVICES=""

# --- Installation helpers ---------------------------------------------------
# Torch CPU wheels index (used by requirements-extra.txt).
export PIP_EXTRA_INDEX_URL="${PIP_EXTRA_INDEX_URL:-https://download.pytorch.org/whl/cpu}"

# NVIDIA PyPI index (PhysicsNeMo ecosystem). If you need it, temporarily override:
#   PIP_EXTRA_INDEX_URL="https://pypi.nvidia.com" pip install <package>
# export PIP_EXTRA_INDEX_URL="https://pypi.nvidia.com"

# --- MoonLight (STREL) ------------------------------------------------------
# MoonLight needs Java (>=21 recommended by their docs). If your system Java is old,
# point JAVA_HOME to a newer JDK install.
# export JAVA_HOME="/path/to/jdk-21"

# Keep MoonLight memory bounded for demos.
export JDK_JAVA_OPTIONS="${JDK_JAVA_OPTIONS:--Xmx2g -Xms256m}"

# Path to the default MoonLight script used by the "hello" demo.
export PHYSICAL_AI_STL_MLS_PATH="${PHYSICAL_AI_STL_MLS_PATH:-$(pwd)/src/physical_ai_stl/monitors/moonlight_hello.mls}"

# --- SpaTiaL / spatial-spec -------------------------------------------------
# spatial-spec's automaton/planning utilities use MONA via `mona` on PATH (Linux-first).
# Quick install on Ubuntu/Debian:  sudo apt install mona
# If mona is in a non-standard location, prepend it to PATH:
#   export PATH="/opt/mona/bin:${PATH}"
# Optionally set the command name explicitly (convention; used by some wrappers):
#   export MONA_CMD="${MONA_CMD:-mona}"

# --- Misc -------------------------------------------------------------------
# If you want profiler-friendly runs (more verbose, slower), you can enable:
# export TORCH_SHOW_CPP_STACKTRACES=1
# export CUDA_LAUNCH_BLOCKING=1

# End of file.
